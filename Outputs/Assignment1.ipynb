{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee52949f",
   "metadata": {},
   "source": [
    "# Assignemnt 1: Creating a Mini Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048d733-c179-4a97-b02a-e7572cf7c80b",
   "metadata": {},
   "source": [
    "$\\textbf{Programming Assignment}$\n",
    "\n",
    "Choose a topic that you will be using as a term paper for this subject. Collect articles, publications, sotries etc. of your chosen topic and develop your own mini-corpus using the preprocessing steps required. Be sure to print the output.\n",
    "\n",
    "Note that this corpus will be used for the entire subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b736512-9858-4bda-97c9-c3abf00220bf",
   "metadata": {},
   "source": [
    "$\\textbf{Text Vectorization}$\n",
    "-\n",
    "\n",
    "- a vector is a geometric object which contains a magnitude and a direction.\n",
    "\n",
    "- Text vectorization is the projection of words into a mathematical space while preserving information.\n",
    "\n",
    "$\\textbf{The Bag of Words Model}$\n",
    "-\n",
    "\n",
    "- The BOW is a straight forward model for vectorizing sentences.\n",
    "\n",
    "- BOW uses word frequencies to construct vectors.\n",
    "\n",
    "- BOW model is an orderless document representation and only the counts of the words matter.\n",
    "\n",
    "- Because BOW does not take into account the positioning of words we loss smenatic information.\n",
    "\n",
    "- Vectorizing different sentences and joining the result into a single vocabulary.\n",
    "\n",
    "- The vocabulary acts as a reference if a specific word is present or absent in each of the sentence.\n",
    "\n",
    "$EXAMPLE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15453f40-a0f4-4f3a-8e9f-b1d74636fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mat', 'playing', 'my', 'sat', 'the', 'The', 'with', 'on', 'My', 'cat', 'neighborhood', 'dog', 'loves']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "s1 = \"My dog sat on the mat.\"\n",
    "s2 = \"The neighborhood cat loves playing with my dog.\"\n",
    "\n",
    "def token_sentence(s):\n",
    "    # Make a regular expression that matches all punctuation\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # Use the regex\n",
    "    res = regex.sub('', s)\n",
    "    res = res.split()\n",
    "    return res\n",
    "\n",
    "new_s1 = token_sentence(s1)\n",
    "new_s2 = token_sentence(s2)\n",
    "vocabulary = list(set(new_s1 + new_s2))\n",
    "\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05ca5929-3e4f-4ce7-a40e-ed454af9812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'dog', 'sat', 'on', 'the', 'mat']\n",
      "['The', 'neighborhood', 'cat', 'loves', 'playing', 'with', 'my', 'dog']\n"
     ]
    }
   ],
   "source": [
    "# printing the token sentences\n",
    "print(new_s1)\n",
    "print(new_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87c86c6b-4122-4186-b631-998bd84d378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "BOW1 = [int(u in new_s1) for u in vocabulary]\n",
    "BOW2 = [int(u in new_s2) for u in vocabulary]\n",
    "\n",
    "print(BOW1)\n",
    "print(BOW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07116216-ed5e-421d-95e7-fd69f1115685",
   "metadata": {},
   "source": [
    "$\\text{Term Frequency Inverse Document Frequency (TF-IDF)}$\n",
    "-\n",
    "\n",
    "- A model largely used in search engines to query relevant documents.\n",
    "\n",
    "- Two informations are encoded: the term frequency, and the inverse document frequency.\n",
    "\n",
    "- The term frequency is the count of words appearing in a document.\n",
    "\n",
    "- The inverse document frequency measures the importance of words in a document.\n",
    "\n",
    "- The inverse document frequency is calculated by logarithmically scaling the inverse fraction of the documents containing the word. This is obtained by dividing the total number of documents by the number of documents containing the term, followed by taking the logarithm of the ratio.\n",
    "\n",
    "- The inverse document frequency measures how common or rare a term is among all documents.\n",
    "\n",
    "The formula are:\n",
    "\\begin{gather}\n",
    "TF(t) = \\frac{\\text{number of times the term \"t\" appeas in a specific document}}{\\text{total number of terms in the document}}\n",
    "\\end{gather}\n",
    "\n",
    "\\begin{gather}\n",
    "IDF(t) = log(\\frac{\\text{total number of documents}}{\\text{number of documents with term \"t\"}})\n",
    "\\end{gather}\n",
    "\n",
    "\\begin{gather}\n",
    "TF \\cdotp IDF = TF(t) \\cdotp IDF(t)\n",
    "\\end{gather}\n",
    "\n",
    "- TF-IDF has more information that using vector representation because instead of using the count of words as used in the BOW, TF-IDF makes rare terms more prominent and ignores common words like stopwords such as \"is\", \"that\", \"of\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524507ac-0062-4b88-b0f3-e17f80564ee5",
   "metadata": {},
   "source": [
    "$\\text{Vectorization Using Gensim}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fcda414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the text so as to remove line breaks and excessive spaces\n",
    "def clean_text(text):\n",
    "    # Remove excess spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # Remove line breaks\n",
    "    text = text.replace('\\n', '').replace('\\r', '').replace('\"', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c6784",
   "metadata": {},
   "source": [
    "Fetch articles from arXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8097439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "A numerical study of the properties of Gaussian pulses propagating in planar\n",
      "waveguide under the combined effect of positive Kerr-type nonlinearity,\n",
      "diffraction in planar waveguides and anomalous or normal dispersion, is\n",
      "presented. It is demonstrated how the relative strength of dispersion and\n",
      "diffraction, the strength of nonlinearity and the initial spatial and temporal\n",
      "pulse chirps effect on the parameters of pulse compression, such as the maximal\n",
      "compression factor and the distance to the point of maximal compression.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "We report on a theoretical and numerical investigation of the switching of\n",
      "power in new hybrid models of nonlinear coherent couplers consisting of optical\n",
      "slab waveguides with various orders of nonlinearity. The first model consists\n",
      "of two guides with second-order instead of the usual third-order\n",
      "susceptibilities as typified by the Jensen coupler. This second-order system is\n",
      "shown to have a power self-trapping transition at a critical power greater than\n",
      "the third-order susceptibility coupler. Next, we consider a mixed coupler\n",
      "composed of a second-order guide coupled to a third-order guide and show that,\n",
      "although it does not display a rigorous self-trapping transition, for a\n",
      "particular choice of parameters it does show a fairly abrupt trapping of power\n",
      "at a lower power than in the third-order coupler. By coupling this mixed\n",
      "nonlinear pair to a third, purely linear guide, the power trapping can be\n",
      "brought to even lower levels and in this way a satisfactory switching profile\n",
      "can be achieved at less than one sixth the input power needed in the Jensen\n",
      "coupler.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "It is noted that the Jones-matrix formalism for polarization optics is a\n",
      "six-parameter two-by-two representation of the Lorentz group. It is shown that\n",
      "the four independent Stokes parameters form a Minkowskian four-vector, just\n",
      "like the energy-momentum four-vector in special relativity. The optical filters\n",
      "are represented by four-by-four Lorentz-transformation matrices. This\n",
      "four-by-four formalism can deal with partial coherence described by the Stokes\n",
      "parameters. A four-by-four matrix formulation is given for decoherence effects\n",
      "on the Stokes parameters, and a possible experiment is proposed. It is shown\n",
      "also that this Lorentz-group formalism leads to optical filters with a symmetry\n",
      "property corresponding to that of two-dimensional Euclidean transformations.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "We study the electromagnetic scattering by multilayered biperiodic aggregates\n",
      "of dielectric layers and gratings of conducting plates. We show that the\n",
      "characteristic lengths of such structures provide a good control of absorption\n",
      "bands. The influence of the physical parameters of the problem (sizes,\n",
      "impedances) is discussed.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "The propagation of an electromagnetic pulse in a plasma is studied for pulse\n",
      "durations that are comparable to the plasma period. When the carrier frequency\n",
      "of the incident pulse is much higher than the plasma frequency, the pulse\n",
      "propagates without distortion at its group speed. When the carrier frequency is\n",
      "comparable to the plasma frequency, the pulse is distorted and leaves behind it\n",
      "an electromagnetic wake.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "We present scattering from many body systems in a new light. In place of the\n",
      "usual van Hove treatment, (applicable to a wide range of scattering processes\n",
      "using both photons and massive particles) based on plane waves, we calculate\n",
      "the scattering amplitude as a space-time integral over the scattering sample\n",
      "for an incident wave characterized by its correlation function which results\n",
      "from the shaping of the wave field by the apparatus. Instrument resolution\n",
      "effects - seen as due to the loss of correlation caused by the path differences\n",
      "in the different arms of the instrument are automatically included and analytic\n",
      "forms of the resolution function for different instruments are obtained. The\n",
      "intersection of the moving correlation volumes (those regions where the\n",
      "correlation functions are significant) associated with the different elements\n",
      "of the apparatus determines the maximum correlation lengths (times) that can be\n",
      "observed in a sample, and hence, the momentum (energy) resolution of the\n",
      "measurement. This geometrical picture of moving correlation volumes derived by\n",
      "our technique shows how the interaction of the scatterer with the wave field\n",
      "shaped by the apparatus proceeds in space and time. Matching of the correlation\n",
      "volumes so as to maximize the intersection region yields a transparent,\n",
      "graphical method of instrument design. PACS: 03.65.Nk, 3.80 +r, 03.75, 61.12.B\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "In this paper we extend for the case of Maxwell equations the \"X-shaped\"\n",
      "solutions previously found in the case of scalar (e.g., acoustic) wave\n",
      "equations. Such solutions are localized in theory, i.e., diffraction-free and\n",
      "particle-like (wavelets), in that they maintain their shape as they propagate.\n",
      "In the electromagnetic case they are particularly interesting, since they are\n",
      "expected to be Superluminal. We address also the problem of their practical,\n",
      "approximate production by finite (dynamic) radiators. Finally, we discuss the\n",
      "appearance of the X-shaped solutions from the purely geometric point of view of\n",
      "the Special Relativity theory.\n",
      "  [PACS nos.: 03.50.De; 1.20.Jb; 03.30.+p; 03.40.Kf; 14.80.-j.\n",
      "  Keywords: X-shaped waves; localized solutions to Maxwell equations;\n",
      "Superluminal waves; Bessel beams; Limited-dispersion beams; electromagnetic\n",
      "wavelets; Special Relativity; Extended Relativity].\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "This paper has been withdrawn by the authors until some changes are made.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "The effect of dispersion or diffraction on zero-velocity solitons is studied\n",
      "for the generalized massive Thirring model describing a nonlinear optical fiber\n",
      "with grating or parallel-coupled planar waveguides with misaligned axes. The\n",
      "Thirring solitons existing at zero dispersion/diffraction are shown numerically\n",
      "to be separated by a finite gap from three isolated soliton branches. Inside\n",
      "the gap, there is an infinity of multi-soliton branches. Thus, the Thirring\n",
      "solitons are structurally unstable. In another parameter region (far from the\n",
      "Thirring limit), solitons exist everywhere.\n",
      "['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'keymap', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "We theoretically study reflection of light by a phase-conjugating mirror\n",
      "preceded by a partially reflecting normal mirror. The presence of a suitably\n",
      "chosen normal mirror in front of the phase conjugator is found to greatly\n",
      "enhance the total phase-conjugate reflected power, even up to an order of\n",
      "magnitude. Required conditions are that the phase-conjugating mirror itself\n",
      "amplifies upon reflection and that constructive interference of light in the\n",
      "region between the mirrors takes place. We show that the phase-conjugate\n",
      "reflected power then exhibits a maximum as a function of the transmittance of\n",
      "the normal mirror.\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "n_papers = 10\n",
    "chunk_size = 10\n",
    "category = 'physics.optics'\n",
    "for chunk_i in range(0, n_papers, chunk_size): \n",
    "   feed = feedparser.parse('http://export.arxiv.org/api/query?search_query=cat:%s&start=%d&max_results=%d' % (category, chunk_i,chunk_size))\n",
    "   \n",
    "   for i in range(len(feed.entries)):\n",
    "       entry = feed.entries[i]\n",
    "       title = (entry.title).replace('\\n', \"\") #removes newlines\n",
    "       print(dir(entry))\n",
    "       with open('files\\\\assignment1\\\\'+clean_text(title)+'.txt', 'w') as f:\n",
    "            f.write(clean_text(entry.summary))\n",
    "\n",
    "       print(entry.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e0be93f-0819-40a8-9604-4da4916737f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC 05\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ..\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c080192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Numerical Study of Absorption by Multilayered Biperiodic Structures.txt', 'Giant phase-conjugate reflection with a normal mirror in front of an optical phase-conjugator.txt', 'Numerical Study on Space-Time Pulse Compression.txt', 'On Localized X-shaped Superluminal Solutions to Maxwell Equations.txt', 'Power Switching in Hybrid Coherent Couplers.txt', 'Propagation of a short laser pulse in a plasma.txt', 'Scattering Integral Equations for Diffusive Waves. Detection of Objects Buried in Diffusive Media in the Presence of Interfaces.txt', 'Space-Time Approach to Scattering from Many Body Systems.txt', 'Stokes Parameters as a Minkowskian Four-vector.txt', 'Thirring Solitons in the presence of dispersion.txt']\n",
      "We study the electromagnetic scattering by multilayered biperiodic aggregates of dielectric layers and gratings of conducting plates. We show that the characteristic lengths of such structures provide a good control of absorption bands. The influence of the physical parameters of the problem (sizes, impedances) is discussed.\n",
      "We theoretically study reflection of light by a phase-conjugating mirror preceded by a partially reflecting normal mirror. The presence of a suitably chosen normal mirror in front of the phase conjugator is found to greatly enhance the total phase-conjugate reflected power, even up to an order of magnitude. Required conditions are that the phase-conjugating mirror itself amplifies upon reflection and that constructive interference of light in the region between the mirrors takes place. We show that the phase-conjugate reflected power then exhibits a maximum as a function of the transmittance of the normal mirror.\n",
      "A numerical study of the properties of Gaussian pulses propagating in planar waveguide under the combined effect of positive Kerr-type nonlinearity, diffraction in planar waveguides and anomalous or normal dispersion, is presented. It is demonstrated how the relative strength of dispersion and diffraction, the strength of nonlinearity and the initial spatial and temporal pulse chirps effect on the parameters of pulse compression, such as the maximal compression factor and the distance to the point of maximal compression.\n",
      "In this paper we extend for the case of Maxwell equations the X-shaped solutions previously found in the case of scalar (e.g., acoustic) wave equations. Such solutions are localized in theory, i.e., diffraction-free and particle-like (wavelets), in that they maintain their shape as they propagate. In the electromagnetic case they are particularly interesting, since they are expected to be Superluminal. We address also the problem of their practical, approximate production by finite (dynamic) radiators. Finally, we discuss the appearance of the X-shaped solutions from the purely geometric point of view of the Special Relativity theory. [PACS nos.: 03.50.De; 1.20.Jb; 03.30.+p; 03.40.Kf; 14.80.-j. Keywords: X-shaped waves; localized solutions to Maxwell equations; Superluminal waves; Bessel beams; Limited-dispersion beams; electromagnetic wavelets; Special Relativity; Extended Relativity].\n",
      "We report on a theoretical and numerical investigation of the switching of power in new hybrid models of nonlinear coherent couplers consisting of optical slab waveguides with various orders of nonlinearity. The first model consists of two guides with second-order instead of the usual third-order susceptibilities as typified by the Jensen coupler. This second-order system is shown to have a power self-trapping transition at a critical power greater than the third-order susceptibility coupler. Next, we consider a mixed coupler composed of a second-order guide coupled to a third-order guide and show that, although it does not display a rigorous self-trapping transition, for a particular choice of parameters it does show a fairly abrupt trapping of power at a lower power than in the third-order coupler. By coupling this mixed nonlinear pair to a third, purely linear guide, the power trapping can be brought to even lower levels and in this way a satisfactory switching profile can be achieved at less than one sixth the input power needed in the Jensen coupler.\n",
      "The propagation of an electromagnetic pulse in a plasma is studied for pulse durations that are comparable to the plasma period. When the carrier frequency of the incident pulse is much higher than the plasma frequency, the pulse propagates without distortion at its group speed. When the carrier frequency is comparable to the plasma frequency, the pulse is distorted and leaves behind it an electromagnetic wake.\n",
      "This paper has been withdrawn by the authors until some changes are made.\n",
      "We present scattering from many body systems in a new light. In place of the usual van Hove treatment, (applicable to a wide range of scattering processes using both photons and massive particles) based on plane waves, we calculate the scattering amplitude as a space-time integral over the scattering sample for an incident wave characterized by its correlation function which results from the shaping of the wave field by the apparatus. Instrument resolution effects - seen as due to the loss of correlation caused by the path differences in the different arms of the instrument are automatically included and analytic forms of the resolution function for different instruments are obtained. The intersection of the moving correlation volumes (those regions where the correlation functions are significant) associated with the different elements of the apparatus determines the maximum correlation lengths (times) that can be observed in a sample, and hence, the momentum (energy) resolution of the measurement. This geometrical picture of moving correlation volumes derived by our technique shows how the interaction of the scatterer with the wave field shaped by the apparatus proceeds in space and time. Matching of the correlation volumes so as to maximize the intersection region yields a transparent, graphical method of instrument design. PACS: 03.65.Nk, 3.80 +r, 03.75, 61.12.B\n",
      "It is noted that the Jones-matrix formalism for polarization optics is a six-parameter two-by-two representation of the Lorentz group. It is shown that the four independent Stokes parameters form a Minkowskian four-vector, just like the energy-momentum four-vector in special relativity. The optical filters are represented by four-by-four Lorentz-transformation matrices. This four-by-four formalism can deal with partial coherence described by the Stokes parameters. A four-by-four matrix formulation is given for decoherence effects on the Stokes parameters, and a possible experiment is proposed. It is shown also that this Lorentz-group formalism leads to optical filters with a symmetry property corresponding to that of two-dimensional Euclidean transformations.\n",
      "The effect of dispersion or diffraction on zero-velocity solitons is studied for the generalized massive Thirring model describing a nonlinear optical fiber with grating or parallel-coupled planar waveguides with misaligned axes. The Thirring solitons existing at zero dispersion/diffraction are shown numerically to be separated by a finite gap from three isolated soliton branches. Inside the gap, there is an infinity of multi-soliton branches. Thus, the Thirring solitons are structurally unstable. In another parameter region (far from the Thirring limit), solitons exist everywhere.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# folder path\n",
    "dir_path = 'files\\\\assignment1'\n",
    "\n",
    "# list to store file names\n",
    "res = []\n",
    "\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        res.append(path)\n",
    "print(res)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file in res:\n",
    "    f = open(dir_path + '\\\\' + file, \"r\")\n",
    "\n",
    "    doc = f.read()\n",
    "    clean_doc = clean_text(doc)\n",
    "    documents.append(clean_doc)\n",
    "    print(clean_doc)\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b506768-b958-45c7-b94a-e50ac8ea6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['study', 'electromagnetic', 'scattering', 'multilayere', 'biperiodic', 'aggregate', 'dielectric', 'layer', 'grating', 'conduct', 'plate', 'characteristic', 'length', 'structure', 'provide', 'good', 'control', 'absorption', 'band', 'influence', 'physical', 'parameter', 'problem', 'size', 'impedance', 'discuss'], ['theoretically', 'study', 'reflection', 'light', 'phase', 'conjugate', 'mirror', 'precede', 'partially', 'reflect', 'normal', 'mirror', 'presence', 'suitably', 'choose', 'normal', 'mirror', 'phase', 'conjugator', 'find', 'greatly', 'enhance', 'total', 'phase', 'conjugate', 'reflected', 'power', 'order', 'magnitude', 'require', 'condition', 'phase', 'conjugate', 'mirror', 'amplifie', 'reflection', 'constructive', 'interference', 'light', 'region', 'mirror', 'take', 'place', 'phase', 'conjugate', 'reflect', 'power', 'exhibit', 'maximum', 'function', 'transmittance', 'normal', 'mirror'], ['numerical', 'study', 'property', 'Gaussian', 'pulse', 'propagate', 'planar', 'waveguide', 'combine', 'effect', 'positive', 'Kerr', 'type', 'nonlinearity', 'diffraction', 'planar', 'waveguide', 'anomalous', 'normal', 'dispersion', 'present', 'demonstrate', 'relative', 'strength', 'dispersion', 'diffraction', 'strength', 'nonlinearity', 'initial', 'spatial', 'temporal', 'pulse', 'chirp', 'effect', 'parameter', 'pulse', 'compression', 'maximal', 'compression', 'factor', 'distance', 'point', 'maximal', 'compression'], ['paper', 'extend', 'case', 'Maxwell', 'equation', 'x', 'shape', 'solution', 'previously', 'find', 'case', 'scalar', 'e.g.', 'acoustic', 'wave', 'equation', 'solution', 'localize', 'theory', 'i.e.', 'diffraction', 'free', 'particle', 'like', 'wavelet', 'maintain', 'shape', 'propagate', 'electromagnetic', 'case', 'particularly', 'interesting', 'expect', 'superluminal', 'address', 'problem', 'practical', 'approximate', 'production', 'finite', 'dynamic', 'radiator', 'finally', 'discuss', 'appearance', 'x', 'shape', 'solution', 'purely', 'geometric', 'point', 'view', 'Special', 'Relativity', 'theory', 'pac', 'nos', '03.50.de', '1.20.Jb', '03.30.+p', '03.40.kf', '14.80.-j', 'keyword', 'x', 'shape', 'wave', 'localize', 'solution', 'Maxwell', 'equation', 'superluminal', 'wave', 'Bessel', 'beam', 'limited', 'dispersion', 'beam', 'electromagnetic', 'wavelet', 'Special', 'Relativity', 'Extended', 'Relativity'], ['report', 'theoretical', 'numerical', 'investigation', 'switching', 'power', 'new', 'hybrid', 'model', 'nonlinear', 'coherent', 'coupler', 'consist', 'optical', 'slab', 'waveguide', 'order', 'nonlinearity', 'model', 'consist', 'guide', 'order', 'instead', 'usual', 'order', 'susceptibility', 'typify', 'Jensen', 'coupler', 'order', 'system', 'show', 'power', 'self', 'trap', 'transition', 'critical', 'power', 'great', 'order', 'susceptibility', 'coupler', 'consider', 'mixed', 'coupler', 'compose', 'order', 'guide', 'couple', 'order', 'guide', 'display', 'rigorous', 'self', 'trap', 'transition', 'particular', 'choice', 'parameter', 'fairly', 'abrupt', 'trapping', 'power', 'low', 'power', 'order', 'coupler', 'couple', 'mixed', 'nonlinear', 'pair', 'purely', 'linear', 'guide', 'power', 'trapping', 'bring', 'low', 'level', 'way', 'satisfactory', 'switching', 'profile', 'achieve', 'input', 'power', 'need', 'Jensen', 'coupler'], ['propagation', 'electromagnetic', 'pulse', 'plasma', 'study', 'pulse', 'duration', 'comparable', 'plasma', 'period', 'carrier', 'frequency', 'incident', 'pulse', 'high', 'plasma', 'frequency', 'pulse', 'propagate', 'distortion', 'group', 'speed', 'carrier', 'frequency', 'comparable', 'plasma', 'frequency', 'pulse', 'distort', 'leave', 'electromagnetic', 'wake'], ['paper', 'withdraw', 'author', 'change'], ['present', 'scatter', 'body', 'system', 'new', 'light', 'place', 'usual', 'van', 'Hove', 'treatment', 'applicable', 'wide', 'range', 'scatter', 'process', 'photon', 'massive', 'particle', 'base', 'plane', 'wave', 'calculate', 'scatter', 'amplitude', 'space', 'time', 'integral', 'scatter', 'sample', 'incident', 'wave', 'characterize', 'correlation', 'function', 'result', 'shaping', 'wave', 'field', 'apparatus', 'instrument', 'resolution', 'effect', 'see', 'loss', 'correlation', 'cause', 'path', 'difference', 'different', 'arm', 'instrument', 'automatically', 'include', 'analytic', 'form', 'resolution', 'function', 'different', 'instrument', 'obtain', 'intersection', 'move', 'correlation', 'volume', 'region', 'correlation', 'function', 'significant', 'associate', 'different', 'element', 'apparatus', 'determine', 'maximum', 'correlation', 'length', 'times', 'observe', 'sample', 'momentum', 'energy', 'resolution', 'measurement', 'geometrical', 'picture', 'move', 'correlation', 'volume', 'derive', 'technique', 'show', 'interaction', 'scatterer', 'wave', 'field', 'shape', 'apparatus', 'proceed', 'space', 'time', 'matching', 'correlation', 'volume', 'maximize', 'intersection', 'region', 'yield', 'transparent', 'graphical', 'method', 'instrument', 'design', 'PACS', '03.65.nk', '+', 'r', '61.12.b'], ['note', 'Jones', 'matrix', 'formalism', 'polarization', 'optic', 'parameter', 'representation', 'Lorentz', 'group', 'show', 'independent', 'Stokes', 'parameter', 'form', 'minkowskian', 'vector', 'like', 'energy', 'momentum', 'vector', 'special', 'relativity', 'optical', 'filter', 'represent', 'Lorentz', 'transformation', 'matrix', 'formalism', 'deal', 'partial', 'coherence', 'describe', 'Stokes', 'parameter', 'matrix', 'formulation', 'give', 'decoherence', 'effect', 'Stokes', 'parameter', 'possible', 'experiment', 'propose', 'show', 'Lorentz', 'group', 'formalism', 'lead', 'optical', 'filter', 'symmetry', 'property', 'correspond', 'dimensional', 'euclidean', 'transformation'], ['effect', 'dispersion', 'diffraction', 'velocity', 'soliton', 'study', 'generalized', 'massive', 'thirring', 'model', 'describe', 'nonlinear', 'optical', 'fiber', 'grating', 'parallel', 'couple', 'planar', 'waveguide', 'misaligned', 'axis', 'Thirring', 'soliton', 'exist', 'dispersion', 'diffraction', 'show', 'numerically', 'separate', 'finite', 'gap', 'isolate', 'soliton', 'branch', 'inside', 'gap', 'infinity', 'multi', 'soliton', 'branch', 'Thirring', 'soliton', 'structurally', 'unstable', 'parameter', 'region', 'far', 'Thirring', 'limit', 'soliton', 'exist']]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for document in documents:\n",
    "    text = []\n",
    "    doc = nlp(document)\n",
    "    for w in doc:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            text.append(w.lemma_)\n",
    "    texts.append(text)\n",
    "#texts is a mini-corpus specifically for toxic algal bloom\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce52e115-56cb-4821-9a51-2822e46126e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absorption': 0, 'aggregate': 1, 'band': 2, 'biperiodic': 3, 'characteristic': 4, 'conduct': 5, 'control': 6, 'dielectric': 7, 'discuss': 8, 'electromagnetic': 9, 'good': 10, 'grating': 11, 'impedance': 12, 'influence': 13, 'layer': 14, 'length': 15, 'multilayere': 16, 'parameter': 17, 'physical': 18, 'plate': 19, 'problem': 20, 'provide': 21, 'scattering': 22, 'size': 23, 'structure': 24, 'study': 25, 'amplifie': 26, 'choose': 27, 'condition': 28, 'conjugate': 29, 'conjugator': 30, 'constructive': 31, 'enhance': 32, 'exhibit': 33, 'find': 34, 'function': 35, 'greatly': 36, 'interference': 37, 'light': 38, 'magnitude': 39, 'maximum': 40, 'mirror': 41, 'normal': 42, 'order': 43, 'partially': 44, 'phase': 45, 'place': 46, 'power': 47, 'precede': 48, 'presence': 49, 'reflect': 50, 'reflected': 51, 'reflection': 52, 'region': 53, 'require': 54, 'suitably': 55, 'take': 56, 'theoretically': 57, 'total': 58, 'transmittance': 59, 'Gaussian': 60, 'Kerr': 61, 'anomalous': 62, 'chirp': 63, 'combine': 64, 'compression': 65, 'demonstrate': 66, 'diffraction': 67, 'dispersion': 68, 'distance': 69, 'effect': 70, 'factor': 71, 'initial': 72, 'maximal': 73, 'nonlinearity': 74, 'numerical': 75, 'planar': 76, 'point': 77, 'positive': 78, 'present': 79, 'propagate': 80, 'property': 81, 'pulse': 82, 'relative': 83, 'spatial': 84, 'strength': 85, 'temporal': 86, 'type': 87, 'waveguide': 88, '03.30.+p': 89, '03.40.kf': 90, '03.50.de': 91, '1.20.Jb': 92, '14.80.-j': 93, 'Bessel': 94, 'Extended': 95, 'Maxwell': 96, 'Relativity': 97, 'Special': 98, 'acoustic': 99, 'address': 100, 'appearance': 101, 'approximate': 102, 'beam': 103, 'case': 104, 'dynamic': 105, 'e.g.': 106, 'equation': 107, 'expect': 108, 'extend': 109, 'finally': 110, 'finite': 111, 'free': 112, 'geometric': 113, 'i.e.': 114, 'interesting': 115, 'keyword': 116, 'like': 117, 'limited': 118, 'localize': 119, 'maintain': 120, 'nos': 121, 'pac': 122, 'paper': 123, 'particle': 124, 'particularly': 125, 'practical': 126, 'previously': 127, 'production': 128, 'purely': 129, 'radiator': 130, 'scalar': 131, 'shape': 132, 'solution': 133, 'superluminal': 134, 'theory': 135, 'view': 136, 'wave': 137, 'wavelet': 138, 'x': 139, 'Jensen': 140, 'abrupt': 141, 'achieve': 142, 'bring': 143, 'choice': 144, 'coherent': 145, 'compose': 146, 'consider': 147, 'consist': 148, 'couple': 149, 'coupler': 150, 'critical': 151, 'display': 152, 'fairly': 153, 'great': 154, 'guide': 155, 'hybrid': 156, 'input': 157, 'instead': 158, 'investigation': 159, 'level': 160, 'linear': 161, 'low': 162, 'mixed': 163, 'model': 164, 'need': 165, 'new': 166, 'nonlinear': 167, 'optical': 168, 'pair': 169, 'particular': 170, 'profile': 171, 'report': 172, 'rigorous': 173, 'satisfactory': 174, 'self': 175, 'show': 176, 'slab': 177, 'susceptibility': 178, 'switching': 179, 'system': 180, 'theoretical': 181, 'transition': 182, 'trap': 183, 'trapping': 184, 'typify': 185, 'usual': 186, 'way': 187, 'carrier': 188, 'comparable': 189, 'distort': 190, 'distortion': 191, 'duration': 192, 'frequency': 193, 'group': 194, 'high': 195, 'incident': 196, 'leave': 197, 'period': 198, 'plasma': 199, 'propagation': 200, 'speed': 201, 'wake': 202, 'author': 203, 'change': 204, 'withdraw': 205, '+': 206, '03.65.nk': 207, '61.12.b': 208, 'Hove': 209, 'PACS': 210, 'amplitude': 211, 'analytic': 212, 'apparatus': 213, 'applicable': 214, 'arm': 215, 'associate': 216, 'automatically': 217, 'base': 218, 'body': 219, 'calculate': 220, 'cause': 221, 'characterize': 222, 'correlation': 223, 'derive': 224, 'design': 225, 'determine': 226, 'difference': 227, 'different': 228, 'element': 229, 'energy': 230, 'field': 231, 'form': 232, 'geometrical': 233, 'graphical': 234, 'include': 235, 'instrument': 236, 'integral': 237, 'interaction': 238, 'intersection': 239, 'loss': 240, 'massive': 241, 'matching': 242, 'maximize': 243, 'measurement': 244, 'method': 245, 'momentum': 246, 'move': 247, 'observe': 248, 'obtain': 249, 'path': 250, 'photon': 251, 'picture': 252, 'plane': 253, 'proceed': 254, 'process': 255, 'r': 256, 'range': 257, 'resolution': 258, 'result': 259, 'sample': 260, 'scatter': 261, 'scatterer': 262, 'see': 263, 'shaping': 264, 'significant': 265, 'space': 266, 'technique': 267, 'time': 268, 'times': 269, 'transparent': 270, 'treatment': 271, 'van': 272, 'volume': 273, 'wide': 274, 'yield': 275, 'Jones': 276, 'Lorentz': 277, 'Stokes': 278, 'coherence': 279, 'correspond': 280, 'deal': 281, 'decoherence': 282, 'describe': 283, 'dimensional': 284, 'euclidean': 285, 'experiment': 286, 'filter': 287, 'formalism': 288, 'formulation': 289, 'give': 290, 'independent': 291, 'lead': 292, 'matrix': 293, 'minkowskian': 294, 'note': 295, 'optic': 296, 'partial': 297, 'polarization': 298, 'possible': 299, 'propose': 300, 'relativity': 301, 'represent': 302, 'representation': 303, 'special': 304, 'symmetry': 305, 'transformation': 306, 'vector': 307, 'Thirring': 308, 'axis': 309, 'branch': 310, 'exist': 311, 'far': 312, 'fiber': 313, 'gap': 314, 'generalized': 315, 'infinity': 316, 'inside': 317, 'isolate': 318, 'limit': 319, 'misaligned': 320, 'multi': 321, 'numerically': 322, 'parallel': 323, 'separate': 324, 'soliton': 325, 'structurally': 326, 'thirring': 327, 'unstable': 328, 'velocity': 329}\n"
     ]
    }
   ],
   "source": [
    "#creating a BOW representation of the mini-corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c05e0-56b6-4b11-b502-df817f675c57",
   "metadata": {},
   "source": [
    "$INSIGHTS$\n",
    "\n",
    "- There are 329 unique words in our corpus that is focused on healthcare and toxic algal bloom.\n",
    "\n",
    "- Each word is indexed with an integer.\n",
    "\n",
    "- The index is termed as a \"word ID\".\n",
    "\n",
    "- The BOW now can be used for word integer-id mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5abbe-918d-45b7-8e38-8f0e00c2db1e",
   "metadata": {},
   "source": [
    "Using the doc2bow method, which, as the name suggests, helps convert our document to bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "801b1848-d1c6-435e-8ee8-c7c50c572f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1)],\n",
       " [(25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 4),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 1),\n",
       "  (37, 1),\n",
       "  (38, 2),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 6),\n",
       "  (42, 3),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 5),\n",
       "  (46, 1),\n",
       "  (47, 2),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (50, 2),\n",
       "  (51, 1),\n",
       "  (52, 2),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (55, 1),\n",
       "  (56, 1),\n",
       "  (57, 1),\n",
       "  (58, 1),\n",
       "  (59, 1)],\n",
       " [(17, 1),\n",
       "  (25, 1),\n",
       "  (42, 1),\n",
       "  (60, 1),\n",
       "  (61, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 1),\n",
       "  (65, 3),\n",
       "  (66, 1),\n",
       "  (67, 2),\n",
       "  (68, 2),\n",
       "  (69, 1),\n",
       "  (70, 2),\n",
       "  (71, 1),\n",
       "  (72, 1),\n",
       "  (73, 2),\n",
       "  (74, 2),\n",
       "  (75, 1),\n",
       "  (76, 2),\n",
       "  (77, 1),\n",
       "  (78, 1),\n",
       "  (79, 1),\n",
       "  (80, 1),\n",
       "  (81, 1),\n",
       "  (82, 3),\n",
       "  (83, 1),\n",
       "  (84, 1),\n",
       "  (85, 2),\n",
       "  (86, 1),\n",
       "  (87, 1),\n",
       "  (88, 2)],\n",
       " [(8, 1),\n",
       "  (9, 2),\n",
       "  (20, 1),\n",
       "  (34, 1),\n",
       "  (67, 1),\n",
       "  (68, 1),\n",
       "  (77, 1),\n",
       "  (80, 1),\n",
       "  (89, 1),\n",
       "  (90, 1),\n",
       "  (91, 1),\n",
       "  (92, 1),\n",
       "  (93, 1),\n",
       "  (94, 1),\n",
       "  (95, 1),\n",
       "  (96, 2),\n",
       "  (97, 3),\n",
       "  (98, 2),\n",
       "  (99, 1),\n",
       "  (100, 1),\n",
       "  (101, 1),\n",
       "  (102, 1),\n",
       "  (103, 2),\n",
       "  (104, 3),\n",
       "  (105, 1),\n",
       "  (106, 1),\n",
       "  (107, 3),\n",
       "  (108, 1),\n",
       "  (109, 1),\n",
       "  (110, 1),\n",
       "  (111, 1),\n",
       "  (112, 1),\n",
       "  (113, 1),\n",
       "  (114, 1),\n",
       "  (115, 1),\n",
       "  (116, 1),\n",
       "  (117, 1),\n",
       "  (118, 1),\n",
       "  (119, 2),\n",
       "  (120, 1),\n",
       "  (121, 1),\n",
       "  (122, 1),\n",
       "  (123, 1),\n",
       "  (124, 1),\n",
       "  (125, 1),\n",
       "  (126, 1),\n",
       "  (127, 1),\n",
       "  (128, 1),\n",
       "  (129, 1),\n",
       "  (130, 1),\n",
       "  (131, 1),\n",
       "  (132, 4),\n",
       "  (133, 4),\n",
       "  (134, 2),\n",
       "  (135, 2),\n",
       "  (136, 1),\n",
       "  (137, 3),\n",
       "  (138, 2),\n",
       "  (139, 3)],\n",
       " [(17, 1),\n",
       "  (43, 8),\n",
       "  (47, 7),\n",
       "  (74, 1),\n",
       "  (75, 1),\n",
       "  (88, 1),\n",
       "  (129, 1),\n",
       "  (140, 2),\n",
       "  (141, 1),\n",
       "  (142, 1),\n",
       "  (143, 1),\n",
       "  (144, 1),\n",
       "  (145, 1),\n",
       "  (146, 1),\n",
       "  (147, 1),\n",
       "  (148, 2),\n",
       "  (149, 2),\n",
       "  (150, 6),\n",
       "  (151, 1),\n",
       "  (152, 1),\n",
       "  (153, 1),\n",
       "  (154, 1),\n",
       "  (155, 4),\n",
       "  (156, 1),\n",
       "  (157, 1),\n",
       "  (158, 1),\n",
       "  (159, 1),\n",
       "  (160, 1),\n",
       "  (161, 1),\n",
       "  (162, 2),\n",
       "  (163, 2),\n",
       "  (164, 2),\n",
       "  (165, 1),\n",
       "  (166, 1),\n",
       "  (167, 2),\n",
       "  (168, 1),\n",
       "  (169, 1),\n",
       "  (170, 1),\n",
       "  (171, 1),\n",
       "  (172, 1),\n",
       "  (173, 1),\n",
       "  (174, 1),\n",
       "  (175, 2),\n",
       "  (176, 1),\n",
       "  (177, 1),\n",
       "  (178, 2),\n",
       "  (179, 2),\n",
       "  (180, 1),\n",
       "  (181, 1),\n",
       "  (182, 2),\n",
       "  (183, 2),\n",
       "  (184, 2),\n",
       "  (185, 1),\n",
       "  (186, 1),\n",
       "  (187, 1)],\n",
       " [(9, 2),\n",
       "  (25, 1),\n",
       "  (80, 1),\n",
       "  (82, 5),\n",
       "  (188, 2),\n",
       "  (189, 2),\n",
       "  (190, 1),\n",
       "  (191, 1),\n",
       "  (192, 1),\n",
       "  (193, 4),\n",
       "  (194, 1),\n",
       "  (195, 1),\n",
       "  (196, 1),\n",
       "  (197, 1),\n",
       "  (198, 1),\n",
       "  (199, 4),\n",
       "  (200, 1),\n",
       "  (201, 1),\n",
       "  (202, 1)],\n",
       " [(123, 1), (203, 1), (204, 1), (205, 1)],\n",
       " [(15, 1),\n",
       "  (35, 3),\n",
       "  (38, 1),\n",
       "  (40, 1),\n",
       "  (46, 1),\n",
       "  (53, 2),\n",
       "  (70, 1),\n",
       "  (79, 1),\n",
       "  (124, 1),\n",
       "  (132, 1),\n",
       "  (137, 4),\n",
       "  (166, 1),\n",
       "  (176, 1),\n",
       "  (180, 1),\n",
       "  (186, 1),\n",
       "  (196, 1),\n",
       "  (206, 1),\n",
       "  (207, 1),\n",
       "  (208, 1),\n",
       "  (209, 1),\n",
       "  (210, 1),\n",
       "  (211, 1),\n",
       "  (212, 1),\n",
       "  (213, 3),\n",
       "  (214, 1),\n",
       "  (215, 1),\n",
       "  (216, 1),\n",
       "  (217, 1),\n",
       "  (218, 1),\n",
       "  (219, 1),\n",
       "  (220, 1),\n",
       "  (221, 1),\n",
       "  (222, 1),\n",
       "  (223, 7),\n",
       "  (224, 1),\n",
       "  (225, 1),\n",
       "  (226, 1),\n",
       "  (227, 1),\n",
       "  (228, 3),\n",
       "  (229, 1),\n",
       "  (230, 1),\n",
       "  (231, 2),\n",
       "  (232, 1),\n",
       "  (233, 1),\n",
       "  (234, 1),\n",
       "  (235, 1),\n",
       "  (236, 4),\n",
       "  (237, 1),\n",
       "  (238, 1),\n",
       "  (239, 2),\n",
       "  (240, 1),\n",
       "  (241, 1),\n",
       "  (242, 1),\n",
       "  (243, 1),\n",
       "  (244, 1),\n",
       "  (245, 1),\n",
       "  (246, 1),\n",
       "  (247, 2),\n",
       "  (248, 1),\n",
       "  (249, 1),\n",
       "  (250, 1),\n",
       "  (251, 1),\n",
       "  (252, 1),\n",
       "  (253, 1),\n",
       "  (254, 1),\n",
       "  (255, 1),\n",
       "  (256, 1),\n",
       "  (257, 1),\n",
       "  (258, 3),\n",
       "  (259, 1),\n",
       "  (260, 2),\n",
       "  (261, 4),\n",
       "  (262, 1),\n",
       "  (263, 1),\n",
       "  (264, 1),\n",
       "  (265, 1),\n",
       "  (266, 2),\n",
       "  (267, 1),\n",
       "  (268, 2),\n",
       "  (269, 1),\n",
       "  (270, 1),\n",
       "  (271, 1),\n",
       "  (272, 1),\n",
       "  (273, 3),\n",
       "  (274, 1),\n",
       "  (275, 1)],\n",
       " [(17, 4),\n",
       "  (70, 1),\n",
       "  (81, 1),\n",
       "  (117, 1),\n",
       "  (168, 2),\n",
       "  (176, 2),\n",
       "  (194, 2),\n",
       "  (230, 1),\n",
       "  (232, 1),\n",
       "  (246, 1),\n",
       "  (276, 1),\n",
       "  (277, 3),\n",
       "  (278, 3),\n",
       "  (279, 1),\n",
       "  (280, 1),\n",
       "  (281, 1),\n",
       "  (282, 1),\n",
       "  (283, 1),\n",
       "  (284, 1),\n",
       "  (285, 1),\n",
       "  (286, 1),\n",
       "  (287, 2),\n",
       "  (288, 3),\n",
       "  (289, 1),\n",
       "  (290, 1),\n",
       "  (291, 1),\n",
       "  (292, 1),\n",
       "  (293, 3),\n",
       "  (294, 1),\n",
       "  (295, 1),\n",
       "  (296, 1),\n",
       "  (297, 1),\n",
       "  (298, 1),\n",
       "  (299, 1),\n",
       "  (300, 1),\n",
       "  (301, 1),\n",
       "  (302, 1),\n",
       "  (303, 1),\n",
       "  (304, 1),\n",
       "  (305, 1),\n",
       "  (306, 2),\n",
       "  (307, 2)],\n",
       " [(11, 1),\n",
       "  (17, 1),\n",
       "  (25, 1),\n",
       "  (53, 1),\n",
       "  (67, 2),\n",
       "  (68, 2),\n",
       "  (70, 1),\n",
       "  (76, 1),\n",
       "  (88, 1),\n",
       "  (111, 1),\n",
       "  (149, 1),\n",
       "  (164, 1),\n",
       "  (167, 1),\n",
       "  (168, 1),\n",
       "  (176, 1),\n",
       "  (241, 1),\n",
       "  (283, 1),\n",
       "  (308, 3),\n",
       "  (309, 1),\n",
       "  (310, 2),\n",
       "  (311, 2),\n",
       "  (312, 1),\n",
       "  (313, 1),\n",
       "  (314, 2),\n",
       "  (315, 1),\n",
       "  (316, 1),\n",
       "  (317, 1),\n",
       "  (318, 1),\n",
       "  (319, 1),\n",
       "  (320, 1),\n",
       "  (321, 1),\n",
       "  (322, 1),\n",
       "  (323, 1),\n",
       "  (324, 1),\n",
       "  (325, 6),\n",
       "  (326, 1),\n",
       "  (327, 1),\n",
       "  (328, 1),\n",
       "  (329, 1)]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bb77c-6c24-4c81-87b6-267220cfabcb",
   "metadata": {},
   "source": [
    "- The output is a nested list.\n",
    "\n",
    "- Each individual sublist represents a documents bag-of-words representation.\n",
    "\n",
    "- A reminder: you might see different numbers in your list, this is because each time you create a dictionary, different mappings will occur.\n",
    "\n",
    "- Unlike the example we demonstrated, where an absence of a word was a 0, we use tuples that represent (word_id, word_count).\n",
    "\n",
    "- We can easily verify this by checking the original sentence, mapping each word to its integer ID and reconstructing our list.\n",
    "\n",
    "- We can also notice in this case each document has not greater than one count of each word - in smaller corpuses, this tends to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd28cb55-4fb5-46fe-8405-dc84d12c7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing your generated corpus\n",
    "\n",
    "corpora.MmCorpus.serialize('mini-corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ae242-51ef-4169-8f5b-f1609372b15b",
   "metadata": {},
   "source": [
    "- It is more memory efficient to store your corpus into the disk and later loading it because at most one vector resides in the RAM at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b091d55-bb06-406c-8832-031cbec45f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.21612403188063795), (1, 0.21612403188063795), (2, 0.21612403188063795), (3, 0.21612403188063795), (4, 0.21612403188063795), (5, 0.21612403188063795), (6, 0.21612403188063795), (7, 0.21612403188063795), (8, 0.15106421550072735), (9, 0.11300666261467564), (10, 0.21612403188063795), (11, 0.15106421550072735), (12, 0.21612403188063795), (13, 0.21612403188063795), (14, 0.21612403188063795), (15, 0.15106421550072735), (16, 0.21612403188063795), (17, 0.06505981637991057), (18, 0.21612403188063795), (19, 0.21612403188063795), (20, 0.15106421550072735), (21, 0.21612403188063795), (22, 0.21612403188063795), (23, 0.21612403188063795), (24, 0.21612403188063795), (25, 0.06505981637991057)]\n",
      "[(25, 0.027936411533166672), (26, 0.0928027503423617), (27, 0.0928027503423617), (28, 0.0928027503423617), (29, 0.3712110013694468), (30, 0.0928027503423617), (31, 0.0928027503423617), (32, 0.0928027503423617), (33, 0.0928027503423617), (34, 0.06486633880919503), (35, 0.06486633880919503), (36, 0.0928027503423617), (37, 0.0928027503423617), (38, 0.12973267761839005), (39, 0.0928027503423617), (40, 0.06486633880919503), (41, 0.5568165020541703), (42, 0.19459901642758506), (43, 0.06486633880919503), (44, 0.0928027503423617), (45, 0.4640137517118085), (46, 0.06486633880919503), (47, 0.12973267761839005), (48, 0.0928027503423617), (49, 0.0928027503423617), (50, 0.1856055006847234), (51, 0.0928027503423617), (52, 0.1856055006847234), (53, 0.04852458565757851), (54, 0.0928027503423617), (55, 0.0928027503423617), (56, 0.0928027503423617), (57, 0.0928027503423617), (58, 0.0928027503423617), (59, 0.0928027503423617)]\n",
      "[(17, 0.04432802164983732), (25, 0.04432802164983732), (42, 0.10292647885953252), (60, 0.14725450050936986), (61, 0.14725450050936986), (62, 0.14725450050936986), (63, 0.14725450050936986), (64, 0.14725450050936986), (65, 0.4417635015281096), (66, 0.14725450050936986), (67, 0.1539924969264443), (68, 0.1539924969264443), (69, 0.14725450050936986), (70, 0.11719691441939041), (71, 0.14725450050936986), (72, 0.14725450050936986), (73, 0.2945090010187397), (74, 0.20585295771906503), (75, 0.10292647885953252), (76, 0.20585295771906503), (77, 0.10292647885953252), (78, 0.14725450050936986), (79, 0.10292647885953252), (80, 0.07699624846322214), (81, 0.10292647885953252), (82, 0.3087794365785976), (83, 0.14725450050936986), (84, 0.14725450050936986), (85, 0.2945090010187397), (86, 0.14725450050936986), (87, 0.14725450050936986), (88, 0.1539924969264443)]\n",
      "[(8, 0.06118035341371822), (9, 0.0915344184452126), (20, 0.06118035341371822), (34, 0.06118035341371822), (67, 0.0457672092226063), (68, 0.0457672092226063), (77, 0.06118035341371822), (80, 0.0457672092226063), (89, 0.08752929744365216), (90, 0.08752929744365216), (91, 0.08752929744365216), (92, 0.08752929744365216), (93, 0.08752929744365216), (94, 0.08752929744365216), (95, 0.08752929744365216), (96, 0.17505859488730433), (97, 0.2625878923309565), (98, 0.17505859488730433), (99, 0.08752929744365216), (100, 0.08752929744365216), (101, 0.08752929744365216), (102, 0.08752929744365216), (103, 0.17505859488730433), (104, 0.2625878923309565), (105, 0.08752929744365216), (106, 0.08752929744365216), (107, 0.2625878923309565), (108, 0.08752929744365216), (109, 0.08752929744365216), (110, 0.08752929744365216), (111, 0.06118035341371822), (112, 0.08752929744365216), (113, 0.08752929744365216), (114, 0.08752929744365216), (115, 0.08752929744365216), (116, 0.08752929744365216), (117, 0.06118035341371822), (118, 0.08752929744365216), (119, 0.17505859488730433), (120, 0.08752929744365216), (121, 0.08752929744365216), (122, 0.08752929744365216), (123, 0.06118035341371822), (124, 0.06118035341371822), (125, 0.08752929744365216), (126, 0.08752929744365216), (127, 0.08752929744365216), (128, 0.08752929744365216), (129, 0.06118035341371822), (130, 0.08752929744365216), (131, 0.08752929744365216), (132, 0.24472141365487288), (133, 0.35011718977460865), (134, 0.17505859488730433), (135, 0.17505859488730433), (136, 0.08752929744365216), (137, 0.18354106024115466), (138, 0.17505859488730433), (139, 0.2625878923309565)]\n",
      "[(17, 0.02214431718985571), (43, 0.4113400978017851), (47, 0.359922585576562), (74, 0.05141751222522314), (75, 0.05141751222522314), (88, 0.03846391706508266), (129, 0.05141751222522314), (140, 0.1471236588301577), (141, 0.07356182941507886), (142, 0.07356182941507886), (143, 0.07356182941507886), (144, 0.07356182941507886), (145, 0.07356182941507886), (146, 0.07356182941507886), (147, 0.07356182941507886), (148, 0.1471236588301577), (149, 0.10283502445044627), (150, 0.4413709764904732), (151, 0.07356182941507886), (152, 0.07356182941507886), (153, 0.07356182941507886), (154, 0.07356182941507886), (155, 0.2942473176603154), (156, 0.07356182941507886), (157, 0.07356182941507886), (158, 0.07356182941507886), (159, 0.07356182941507886), (160, 0.07356182941507886), (161, 0.07356182941507886), (162, 0.1471236588301577), (163, 0.1471236588301577), (164, 0.10283502445044627), (165, 0.07356182941507886), (166, 0.05141751222522314), (167, 0.10283502445044627), (168, 0.03846391706508266), (169, 0.07356182941507886), (170, 0.07356182941507886), (171, 0.07356182941507886), (172, 0.07356182941507886), (173, 0.07356182941507886), (174, 0.07356182941507886), (175, 0.1471236588301577), (176, 0.029273195035367433), (177, 0.07356182941507886), (178, 0.1471236588301577), (179, 0.1471236588301577), (180, 0.05141751222522314), (181, 0.07356182941507886), (182, 0.1471236588301577), (183, 0.1471236588301577), (184, 0.1471236588301577), (185, 0.07356182941507886), (186, 0.05141751222522314), (187, 0.07356182941507886)]\n",
      "[(9, 0.13107990881851023), (25, 0.03773244250166981), (80, 0.06553995440925511), (82, 0.43806009166674553), (188, 0.25068892167003787), (189, 0.25068892167003787), (190, 0.12534446083501893), (191, 0.12534446083501893), (192, 0.12534446083501893), (193, 0.5013778433400757), (194, 0.08761201833334911), (195, 0.12534446083501893), (196, 0.08761201833334911), (197, 0.12534446083501893), (198, 0.12534446083501893), (199, 0.5013778433400757), (200, 0.12534446083501893), (201, 0.12534446083501893), (202, 0.12534446083501893)]\n",
      "[(123, 0.37422732775373485), (203, 0.535398265207717), (204, 0.535398265207717), (205, 0.535398265207717)]\n",
      "[(15, 0.04767460492096287), (35, 0.14302381476288864), (38, 0.04767460492096287), (40, 0.04767460492096287), (46, 0.04767460492096287), (53, 0.07132791807422144), (70, 0.02714227016609374), (79, 0.04767460492096287), (124, 0.04767460492096287), (132, 0.04767460492096287), (137, 0.19069841968385148), (166, 0.04767460492096287), (176, 0.02714227016609374), (180, 0.04767460492096287), (186, 0.04767460492096287), (196, 0.04767460492096287), (206, 0.06820693967583202), (207, 0.06820693967583202), (208, 0.06820693967583202), (209, 0.06820693967583202), (210, 0.06820693967583202), (211, 0.06820693967583202), (212, 0.06820693967583202), (213, 0.20462081902749607), (214, 0.06820693967583202), (215, 0.06820693967583202), (216, 0.06820693967583202), (217, 0.06820693967583202), (218, 0.06820693967583202), (219, 0.06820693967583202), (220, 0.06820693967583202), (221, 0.06820693967583202), (222, 0.06820693967583202), (223, 0.47744857773082416), (224, 0.06820693967583202), (225, 0.06820693967583202), (226, 0.06820693967583202), (227, 0.06820693967583202), (228, 0.20462081902749607), (229, 0.06820693967583202), (230, 0.04767460492096287), (231, 0.13641387935166405), (232, 0.04767460492096287), (233, 0.06820693967583202), (234, 0.06820693967583202), (235, 0.06820693967583202), (236, 0.2728277587033281), (237, 0.06820693967583202), (238, 0.06820693967583202), (239, 0.13641387935166405), (240, 0.06820693967583202), (241, 0.04767460492096287), (242, 0.06820693967583202), (243, 0.06820693967583202), (244, 0.06820693967583202), (245, 0.06820693967583202), (246, 0.04767460492096287), (247, 0.13641387935166405), (248, 0.06820693967583202), (249, 0.06820693967583202), (250, 0.06820693967583202), (251, 0.06820693967583202), (252, 0.06820693967583202), (253, 0.06820693967583202), (254, 0.06820693967583202), (255, 0.06820693967583202), (256, 0.06820693967583202), (257, 0.06820693967583202), (258, 0.20462081902749607), (259, 0.06820693967583202), (260, 0.13641387935166405), (261, 0.2728277587033281), (262, 0.06820693967583202), (263, 0.06820693967583202), (264, 0.06820693967583202), (265, 0.06820693967583202), (266, 0.13641387935166405), (267, 0.06820693967583202), (268, 0.13641387935166405), (269, 0.06820693967583202), (270, 0.06820693967583202), (271, 0.06820693967583202), (272, 0.06820693967583202), (273, 0.20462081902749607), (274, 0.06820693967583202), (275, 0.06820693967583202)]\n",
      "[(17, 0.13443923659207183), (70, 0.04442975097656723), (81, 0.07803956012458517), (117, 0.07803956012458517), (168, 0.11675816423319962), (176, 0.08885950195313445), (194, 0.15607912024917034), (230, 0.07803956012458517), (232, 0.07803956012458517), (246, 0.07803956012458517), (276, 0.11164936927260315), (277, 0.3349481078178095), (278, 0.3349481078178095), (279, 0.11164936927260315), (280, 0.11164936927260315), (281, 0.11164936927260315), (282, 0.11164936927260315), (283, 0.07803956012458517), (284, 0.11164936927260315), (285, 0.11164936927260315), (286, 0.11164936927260315), (287, 0.2232987385452063), (288, 0.3349481078178095), (289, 0.11164936927260315), (290, 0.11164936927260315), (291, 0.11164936927260315), (292, 0.11164936927260315), (293, 0.3349481078178095), (294, 0.11164936927260315), (295, 0.11164936927260315), (296, 0.11164936927260315), (297, 0.11164936927260315), (298, 0.11164936927260315), (299, 0.11164936927260315), (300, 0.11164936927260315), (301, 0.11164936927260315), (302, 0.11164936927260315), (303, 0.11164936927260315), (304, 0.11164936927260315), (305, 0.11164936927260315), (306, 0.2232987385452063), (307, 0.2232987385452063)]\n",
      "[(11, 0.0774656911526484), (17, 0.03336265723439911), (25, 0.03336265723439911), (53, 0.05794978774611153), (67, 0.11589957549222306), (68, 0.11589957549222306), (70, 0.044103033918249296), (76, 0.0774656911526484), (88, 0.05794978774611153), (111, 0.0774656911526484), (149, 0.0774656911526484), (164, 0.0774656911526484), (167, 0.0774656911526484), (168, 0.05794978774611153), (176, 0.044103033918249296), (241, 0.0774656911526484), (283, 0.0774656911526484), (308, 0.3324850451611426), (309, 0.11082834838704753), (310, 0.22165669677409505), (311, 0.22165669677409505), (312, 0.11082834838704753), (313, 0.11082834838704753), (314, 0.22165669677409505), (315, 0.11082834838704753), (316, 0.11082834838704753), (317, 0.11082834838704753), (318, 0.11082834838704753), (319, 0.11082834838704753), (320, 0.11082834838704753), (321, 0.11082834838704753), (322, 0.11082834838704753), (323, 0.11082834838704753), (324, 0.11082834838704753), (325, 0.6649700903222852), (326, 0.11082834838704753), (327, 0.11082834838704753), (328, 0.11082834838704753), (329, 0.11082834838704753)]\n"
     ]
    }
   ],
   "source": [
    "#Converting Bag-of-Words to TF-IDF representation\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "for document in tfidf[corpus]:\n",
    "       print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163e098-a7bb-4b74-9feb-d699bc2de793",
   "metadata": {},
   "source": [
    "- TF-IDF scores: The higher the score, the more important the word in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c612c4-f77c-4992-acb1-54bf9a20b26a",
   "metadata": {},
   "source": [
    "$\\textbf{N-Gramming}$\n",
    "\n",
    "- Context is very important when working with text data.\n",
    "- This context is lost during vector representation because on only the word frequency is taken into account.\n",
    "- An n-gram is a contiguous sequence of n items in the text. In our case, we will be dealing with words being the item, but depending on the use case, it could be even letters, syllables, or sometimes in the case of speech, phonemes.\n",
    "- Mono-gram, n=1\n",
    "- Bi-gram, n = 2.\n",
    "- Tri-gram, n=3\n",
    "- N-Gramming is calculated through the conditional probability of a token given by thr preceding token.\n",
    "- N-Gramming can also be done by calculating words that appear close to each other.\n",
    "- Bi-gramming is also called co-location, it locates pair of words that are very likely to appear close together.\n",
    "- Example: \"New Hampshire\" is one word not \"New\" and \"Hampshire\"\n",
    "- Gensim approaches bigrams by simply combining the two high probability tokens with an underscore. The tokens new and york will now become new_york instead. Similar to the TF- IDF model, bigrams can be created using another Gensim model - Phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3eb89c2-8315-4b7e-82c9-a2b09daa78ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['study',\n",
       "  'electromagnetic',\n",
       "  'scattering',\n",
       "  'multilayere',\n",
       "  'biperiodic',\n",
       "  'aggregate',\n",
       "  'dielectric',\n",
       "  'layer',\n",
       "  'grating',\n",
       "  'conduct',\n",
       "  'plate',\n",
       "  'characteristic',\n",
       "  'length',\n",
       "  'structure',\n",
       "  'provide',\n",
       "  'good',\n",
       "  'control',\n",
       "  'absorption',\n",
       "  'band',\n",
       "  'influence',\n",
       "  'physical',\n",
       "  'parameter',\n",
       "  'problem',\n",
       "  'size',\n",
       "  'impedance',\n",
       "  'discuss'],\n",
       " ['theoretically',\n",
       "  'study',\n",
       "  'reflection',\n",
       "  'light',\n",
       "  'phase',\n",
       "  'conjugate',\n",
       "  'mirror',\n",
       "  'precede',\n",
       "  'partially',\n",
       "  'reflect',\n",
       "  'normal',\n",
       "  'mirror',\n",
       "  'presence',\n",
       "  'suitably',\n",
       "  'choose',\n",
       "  'normal',\n",
       "  'mirror',\n",
       "  'phase',\n",
       "  'conjugator',\n",
       "  'find',\n",
       "  'greatly',\n",
       "  'enhance',\n",
       "  'total',\n",
       "  'phase',\n",
       "  'conjugate',\n",
       "  'reflected',\n",
       "  'power',\n",
       "  'order',\n",
       "  'magnitude',\n",
       "  'require',\n",
       "  'condition',\n",
       "  'phase',\n",
       "  'conjugate',\n",
       "  'mirror',\n",
       "  'amplifie',\n",
       "  'reflection',\n",
       "  'constructive',\n",
       "  'interference',\n",
       "  'light',\n",
       "  'region',\n",
       "  'mirror',\n",
       "  'take',\n",
       "  'place',\n",
       "  'phase',\n",
       "  'conjugate',\n",
       "  'reflect',\n",
       "  'power',\n",
       "  'exhibit',\n",
       "  'maximum',\n",
       "  'function',\n",
       "  'transmittance',\n",
       "  'normal',\n",
       "  'mirror'],\n",
       " ['numerical',\n",
       "  'study',\n",
       "  'property',\n",
       "  'Gaussian',\n",
       "  'pulse',\n",
       "  'propagate',\n",
       "  'planar',\n",
       "  'waveguide',\n",
       "  'combine',\n",
       "  'effect',\n",
       "  'positive',\n",
       "  'Kerr',\n",
       "  'type',\n",
       "  'nonlinearity',\n",
       "  'diffraction',\n",
       "  'planar',\n",
       "  'waveguide',\n",
       "  'anomalous',\n",
       "  'normal',\n",
       "  'dispersion',\n",
       "  'present',\n",
       "  'demonstrate',\n",
       "  'relative',\n",
       "  'strength',\n",
       "  'dispersion',\n",
       "  'diffraction',\n",
       "  'strength',\n",
       "  'nonlinearity',\n",
       "  'initial',\n",
       "  'spatial',\n",
       "  'temporal',\n",
       "  'pulse',\n",
       "  'chirp',\n",
       "  'effect',\n",
       "  'parameter',\n",
       "  'pulse',\n",
       "  'compression',\n",
       "  'maximal',\n",
       "  'compression',\n",
       "  'factor',\n",
       "  'distance',\n",
       "  'point',\n",
       "  'maximal',\n",
       "  'compression'],\n",
       " ['paper',\n",
       "  'extend',\n",
       "  'case',\n",
       "  'Maxwell',\n",
       "  'equation',\n",
       "  'x',\n",
       "  'shape',\n",
       "  'solution',\n",
       "  'previously',\n",
       "  'find',\n",
       "  'case',\n",
       "  'scalar',\n",
       "  'e.g.',\n",
       "  'acoustic',\n",
       "  'wave',\n",
       "  'equation',\n",
       "  'solution',\n",
       "  'localize',\n",
       "  'theory',\n",
       "  'i.e.',\n",
       "  'diffraction',\n",
       "  'free',\n",
       "  'particle',\n",
       "  'like',\n",
       "  'wavelet',\n",
       "  'maintain',\n",
       "  'shape',\n",
       "  'propagate',\n",
       "  'electromagnetic',\n",
       "  'case',\n",
       "  'particularly',\n",
       "  'interesting',\n",
       "  'expect',\n",
       "  'superluminal',\n",
       "  'address',\n",
       "  'problem',\n",
       "  'practical',\n",
       "  'approximate',\n",
       "  'production',\n",
       "  'finite',\n",
       "  'dynamic',\n",
       "  'radiator',\n",
       "  'finally',\n",
       "  'discuss',\n",
       "  'appearance',\n",
       "  'x',\n",
       "  'shape',\n",
       "  'solution',\n",
       "  'purely',\n",
       "  'geometric',\n",
       "  'point',\n",
       "  'view',\n",
       "  'Special',\n",
       "  'Relativity',\n",
       "  'theory',\n",
       "  'pac',\n",
       "  'nos',\n",
       "  '03.50.de',\n",
       "  '1.20.Jb',\n",
       "  '03.30.+p',\n",
       "  '03.40.kf',\n",
       "  '14.80.-j',\n",
       "  'keyword',\n",
       "  'x',\n",
       "  'shape',\n",
       "  'wave',\n",
       "  'localize',\n",
       "  'solution',\n",
       "  'Maxwell',\n",
       "  'equation',\n",
       "  'superluminal',\n",
       "  'wave',\n",
       "  'Bessel',\n",
       "  'beam',\n",
       "  'limited',\n",
       "  'dispersion',\n",
       "  'beam',\n",
       "  'electromagnetic',\n",
       "  'wavelet',\n",
       "  'Special',\n",
       "  'Relativity',\n",
       "  'Extended',\n",
       "  'Relativity'],\n",
       " ['report',\n",
       "  'theoretical',\n",
       "  'numerical',\n",
       "  'investigation',\n",
       "  'switching',\n",
       "  'power',\n",
       "  'new',\n",
       "  'hybrid',\n",
       "  'model',\n",
       "  'nonlinear',\n",
       "  'coherent',\n",
       "  'coupler',\n",
       "  'consist',\n",
       "  'optical',\n",
       "  'slab',\n",
       "  'waveguide',\n",
       "  'order',\n",
       "  'nonlinearity',\n",
       "  'model',\n",
       "  'consist',\n",
       "  'guide',\n",
       "  'order',\n",
       "  'instead',\n",
       "  'usual',\n",
       "  'order',\n",
       "  'susceptibility',\n",
       "  'typify',\n",
       "  'Jensen',\n",
       "  'coupler',\n",
       "  'order',\n",
       "  'system',\n",
       "  'show',\n",
       "  'power',\n",
       "  'self',\n",
       "  'trap',\n",
       "  'transition',\n",
       "  'critical',\n",
       "  'power',\n",
       "  'great',\n",
       "  'order',\n",
       "  'susceptibility',\n",
       "  'coupler',\n",
       "  'consider',\n",
       "  'mixed',\n",
       "  'coupler',\n",
       "  'compose',\n",
       "  'order',\n",
       "  'guide',\n",
       "  'couple',\n",
       "  'order',\n",
       "  'guide',\n",
       "  'display',\n",
       "  'rigorous',\n",
       "  'self',\n",
       "  'trap',\n",
       "  'transition',\n",
       "  'particular',\n",
       "  'choice',\n",
       "  'parameter',\n",
       "  'fairly',\n",
       "  'abrupt',\n",
       "  'trapping',\n",
       "  'power',\n",
       "  'low',\n",
       "  'power',\n",
       "  'order',\n",
       "  'coupler',\n",
       "  'couple',\n",
       "  'mixed',\n",
       "  'nonlinear',\n",
       "  'pair',\n",
       "  'purely',\n",
       "  'linear',\n",
       "  'guide',\n",
       "  'power',\n",
       "  'trapping',\n",
       "  'bring',\n",
       "  'low',\n",
       "  'level',\n",
       "  'way',\n",
       "  'satisfactory',\n",
       "  'switching',\n",
       "  'profile',\n",
       "  'achieve',\n",
       "  'input',\n",
       "  'power',\n",
       "  'need',\n",
       "  'Jensen',\n",
       "  'coupler'],\n",
       " ['propagation',\n",
       "  'electromagnetic',\n",
       "  'pulse',\n",
       "  'plasma',\n",
       "  'study',\n",
       "  'pulse',\n",
       "  'duration',\n",
       "  'comparable',\n",
       "  'plasma',\n",
       "  'period',\n",
       "  'carrier',\n",
       "  'frequency',\n",
       "  'incident',\n",
       "  'pulse',\n",
       "  'high',\n",
       "  'plasma',\n",
       "  'frequency',\n",
       "  'pulse',\n",
       "  'propagate',\n",
       "  'distortion',\n",
       "  'group',\n",
       "  'speed',\n",
       "  'carrier',\n",
       "  'frequency',\n",
       "  'comparable',\n",
       "  'plasma',\n",
       "  'frequency',\n",
       "  'pulse',\n",
       "  'distort',\n",
       "  'leave',\n",
       "  'electromagnetic',\n",
       "  'wake'],\n",
       " ['paper', 'withdraw', 'author', 'change'],\n",
       " ['present',\n",
       "  'scatter',\n",
       "  'body',\n",
       "  'system',\n",
       "  'new',\n",
       "  'light',\n",
       "  'place',\n",
       "  'usual',\n",
       "  'van',\n",
       "  'Hove',\n",
       "  'treatment',\n",
       "  'applicable',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'scatter',\n",
       "  'process',\n",
       "  'photon',\n",
       "  'massive',\n",
       "  'particle',\n",
       "  'base',\n",
       "  'plane',\n",
       "  'wave',\n",
       "  'calculate',\n",
       "  'scatter',\n",
       "  'amplitude',\n",
       "  'space',\n",
       "  'time',\n",
       "  'integral',\n",
       "  'scatter',\n",
       "  'sample',\n",
       "  'incident',\n",
       "  'wave',\n",
       "  'characterize',\n",
       "  'correlation',\n",
       "  'function',\n",
       "  'result',\n",
       "  'shaping',\n",
       "  'wave',\n",
       "  'field',\n",
       "  'apparatus',\n",
       "  'instrument',\n",
       "  'resolution',\n",
       "  'effect',\n",
       "  'see',\n",
       "  'loss',\n",
       "  'correlation',\n",
       "  'cause',\n",
       "  'path',\n",
       "  'difference',\n",
       "  'different',\n",
       "  'arm',\n",
       "  'instrument',\n",
       "  'automatically',\n",
       "  'include',\n",
       "  'analytic',\n",
       "  'form',\n",
       "  'resolution',\n",
       "  'function',\n",
       "  'different',\n",
       "  'instrument',\n",
       "  'obtain',\n",
       "  'intersection',\n",
       "  'move',\n",
       "  'correlation',\n",
       "  'volume',\n",
       "  'region',\n",
       "  'correlation',\n",
       "  'function',\n",
       "  'significant',\n",
       "  'associate',\n",
       "  'different',\n",
       "  'element',\n",
       "  'apparatus',\n",
       "  'determine',\n",
       "  'maximum',\n",
       "  'correlation',\n",
       "  'length',\n",
       "  'times',\n",
       "  'observe',\n",
       "  'sample',\n",
       "  'momentum',\n",
       "  'energy',\n",
       "  'resolution',\n",
       "  'measurement',\n",
       "  'geometrical',\n",
       "  'picture',\n",
       "  'move',\n",
       "  'correlation',\n",
       "  'volume',\n",
       "  'derive',\n",
       "  'technique',\n",
       "  'show',\n",
       "  'interaction',\n",
       "  'scatterer',\n",
       "  'wave',\n",
       "  'field',\n",
       "  'shape',\n",
       "  'apparatus',\n",
       "  'proceed',\n",
       "  'space',\n",
       "  'time',\n",
       "  'matching',\n",
       "  'correlation',\n",
       "  'volume',\n",
       "  'maximize',\n",
       "  'intersection',\n",
       "  'region',\n",
       "  'yield',\n",
       "  'transparent',\n",
       "  'graphical',\n",
       "  'method',\n",
       "  'instrument',\n",
       "  'design',\n",
       "  'PACS',\n",
       "  '03.65.nk',\n",
       "  '+',\n",
       "  'r',\n",
       "  '61.12.b'],\n",
       " ['note',\n",
       "  'Jones',\n",
       "  'matrix',\n",
       "  'formalism',\n",
       "  'polarization',\n",
       "  'optic',\n",
       "  'parameter',\n",
       "  'representation',\n",
       "  'Lorentz',\n",
       "  'group',\n",
       "  'show',\n",
       "  'independent',\n",
       "  'Stokes',\n",
       "  'parameter',\n",
       "  'form',\n",
       "  'minkowskian',\n",
       "  'vector',\n",
       "  'like',\n",
       "  'energy',\n",
       "  'momentum',\n",
       "  'vector',\n",
       "  'special',\n",
       "  'relativity',\n",
       "  'optical',\n",
       "  'filter',\n",
       "  'represent',\n",
       "  'Lorentz',\n",
       "  'transformation',\n",
       "  'matrix',\n",
       "  'formalism',\n",
       "  'deal',\n",
       "  'partial',\n",
       "  'coherence',\n",
       "  'describe',\n",
       "  'Stokes',\n",
       "  'parameter',\n",
       "  'matrix',\n",
       "  'formulation',\n",
       "  'give',\n",
       "  'decoherence',\n",
       "  'effect',\n",
       "  'Stokes',\n",
       "  'parameter',\n",
       "  'possible',\n",
       "  'experiment',\n",
       "  'propose',\n",
       "  'show',\n",
       "  'Lorentz',\n",
       "  'group',\n",
       "  'formalism',\n",
       "  'lead',\n",
       "  'optical',\n",
       "  'filter',\n",
       "  'symmetry',\n",
       "  'property',\n",
       "  'correspond',\n",
       "  'dimensional',\n",
       "  'euclidean',\n",
       "  'transformation'],\n",
       " ['effect',\n",
       "  'dispersion',\n",
       "  'diffraction',\n",
       "  'velocity',\n",
       "  'soliton',\n",
       "  'study',\n",
       "  'generalized',\n",
       "  'massive',\n",
       "  'thirring',\n",
       "  'model',\n",
       "  'describe',\n",
       "  'nonlinear',\n",
       "  'optical',\n",
       "  'fiber',\n",
       "  'grating',\n",
       "  'parallel',\n",
       "  'couple',\n",
       "  'planar',\n",
       "  'waveguide',\n",
       "  'misaligned',\n",
       "  'axis',\n",
       "  'Thirring',\n",
       "  'soliton',\n",
       "  'exist',\n",
       "  'dispersion',\n",
       "  'diffraction',\n",
       "  'show',\n",
       "  'numerically',\n",
       "  'separate',\n",
       "  'finite',\n",
       "  'gap',\n",
       "  'isolate',\n",
       "  'soliton',\n",
       "  'branch',\n",
       "  'inside',\n",
       "  'gap',\n",
       "  'infinity',\n",
       "  'multi',\n",
       "  'soliton',\n",
       "  'branch',\n",
       "  'Thirring',\n",
       "  'soliton',\n",
       "  'structurally',\n",
       "  'unstable',\n",
       "  'parameter',\n",
       "  'region',\n",
       "  'far',\n",
       "  'Thirring',\n",
       "  'limit',\n",
       "  'soliton',\n",
       "  'exist']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "bigram = gensim.models.Phrases(texts)\n",
    "texts = [bigram[line] for line in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c48145-2d7d-4bef-9c83-622cce63c0ab",
   "metadata": {},
   "source": [
    "$\\textbf{NOTE}:$ Since by creating new phrases we add words to our dictionary, this step must be done before we create our dictionary. We would have to run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afbd5839-6714-4498-a6f3-c2086ba06d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absorption': 0, 'aggregate': 1, 'band': 2, 'biperiodic': 3, 'characteristic': 4, 'conduct': 5, 'control': 6, 'dielectric': 7, 'discuss': 8, 'electromagnetic': 9, 'good': 10, 'grating': 11, 'impedance': 12, 'influence': 13, 'layer': 14, 'length': 15, 'multilayere': 16, 'parameter': 17, 'physical': 18, 'plate': 19, 'problem': 20, 'provide': 21, 'scattering': 22, 'size': 23, 'structure': 24, 'study': 25, 'amplifie': 26, 'choose': 27, 'condition': 28, 'conjugate': 29, 'conjugator': 30, 'constructive': 31, 'enhance': 32, 'exhibit': 33, 'find': 34, 'function': 35, 'greatly': 36, 'interference': 37, 'light': 38, 'magnitude': 39, 'maximum': 40, 'mirror': 41, 'normal': 42, 'order': 43, 'partially': 44, 'phase': 45, 'place': 46, 'power': 47, 'precede': 48, 'presence': 49, 'reflect': 50, 'reflected': 51, 'reflection': 52, 'region': 53, 'require': 54, 'suitably': 55, 'take': 56, 'theoretically': 57, 'total': 58, 'transmittance': 59, 'Gaussian': 60, 'Kerr': 61, 'anomalous': 62, 'chirp': 63, 'combine': 64, 'compression': 65, 'demonstrate': 66, 'diffraction': 67, 'dispersion': 68, 'distance': 69, 'effect': 70, 'factor': 71, 'initial': 72, 'maximal': 73, 'nonlinearity': 74, 'numerical': 75, 'planar': 76, 'point': 77, 'positive': 78, 'present': 79, 'propagate': 80, 'property': 81, 'pulse': 82, 'relative': 83, 'spatial': 84, 'strength': 85, 'temporal': 86, 'type': 87, 'waveguide': 88, '03.30.+p': 89, '03.40.kf': 90, '03.50.de': 91, '1.20.Jb': 92, '14.80.-j': 93, 'Bessel': 94, 'Extended': 95, 'Maxwell': 96, 'Relativity': 97, 'Special': 98, 'acoustic': 99, 'address': 100, 'appearance': 101, 'approximate': 102, 'beam': 103, 'case': 104, 'dynamic': 105, 'e.g.': 106, 'equation': 107, 'expect': 108, 'extend': 109, 'finally': 110, 'finite': 111, 'free': 112, 'geometric': 113, 'i.e.': 114, 'interesting': 115, 'keyword': 116, 'like': 117, 'limited': 118, 'localize': 119, 'maintain': 120, 'nos': 121, 'pac': 122, 'paper': 123, 'particle': 124, 'particularly': 125, 'practical': 126, 'previously': 127, 'production': 128, 'purely': 129, 'radiator': 130, 'scalar': 131, 'shape': 132, 'solution': 133, 'superluminal': 134, 'theory': 135, 'view': 136, 'wave': 137, 'wavelet': 138, 'x': 139, 'Jensen': 140, 'abrupt': 141, 'achieve': 142, 'bring': 143, 'choice': 144, 'coherent': 145, 'compose': 146, 'consider': 147, 'consist': 148, 'couple': 149, 'coupler': 150, 'critical': 151, 'display': 152, 'fairly': 153, 'great': 154, 'guide': 155, 'hybrid': 156, 'input': 157, 'instead': 158, 'investigation': 159, 'level': 160, 'linear': 161, 'low': 162, 'mixed': 163, 'model': 164, 'need': 165, 'new': 166, 'nonlinear': 167, 'optical': 168, 'pair': 169, 'particular': 170, 'profile': 171, 'report': 172, 'rigorous': 173, 'satisfactory': 174, 'self': 175, 'show': 176, 'slab': 177, 'susceptibility': 178, 'switching': 179, 'system': 180, 'theoretical': 181, 'transition': 182, 'trap': 183, 'trapping': 184, 'typify': 185, 'usual': 186, 'way': 187, 'carrier': 188, 'comparable': 189, 'distort': 190, 'distortion': 191, 'duration': 192, 'frequency': 193, 'group': 194, 'high': 195, 'incident': 196, 'leave': 197, 'period': 198, 'plasma': 199, 'propagation': 200, 'speed': 201, 'wake': 202, 'author': 203, 'change': 204, 'withdraw': 205, '+': 206, '03.65.nk': 207, '61.12.b': 208, 'Hove': 209, 'PACS': 210, 'amplitude': 211, 'analytic': 212, 'apparatus': 213, 'applicable': 214, 'arm': 215, 'associate': 216, 'automatically': 217, 'base': 218, 'body': 219, 'calculate': 220, 'cause': 221, 'characterize': 222, 'correlation': 223, 'derive': 224, 'design': 225, 'determine': 226, 'difference': 227, 'different': 228, 'element': 229, 'energy': 230, 'field': 231, 'form': 232, 'geometrical': 233, 'graphical': 234, 'include': 235, 'instrument': 236, 'integral': 237, 'interaction': 238, 'intersection': 239, 'loss': 240, 'massive': 241, 'matching': 242, 'maximize': 243, 'measurement': 244, 'method': 245, 'momentum': 246, 'move': 247, 'observe': 248, 'obtain': 249, 'path': 250, 'photon': 251, 'picture': 252, 'plane': 253, 'proceed': 254, 'process': 255, 'r': 256, 'range': 257, 'resolution': 258, 'result': 259, 'sample': 260, 'scatter': 261, 'scatterer': 262, 'see': 263, 'shaping': 264, 'significant': 265, 'space': 266, 'technique': 267, 'time': 268, 'times': 269, 'transparent': 270, 'treatment': 271, 'van': 272, 'volume': 273, 'wide': 274, 'yield': 275, 'Jones': 276, 'Lorentz': 277, 'Stokes': 278, 'coherence': 279, 'correspond': 280, 'deal': 281, 'decoherence': 282, 'describe': 283, 'dimensional': 284, 'euclidean': 285, 'experiment': 286, 'filter': 287, 'formalism': 288, 'formulation': 289, 'give': 290, 'independent': 291, 'lead': 292, 'matrix': 293, 'minkowskian': 294, 'note': 295, 'optic': 296, 'partial': 297, 'polarization': 298, 'possible': 299, 'propose': 300, 'relativity': 301, 'represent': 302, 'representation': 303, 'special': 304, 'symmetry': 305, 'transformation': 306, 'vector': 307, 'Thirring': 308, 'axis': 309, 'branch': 310, 'exist': 311, 'far': 312, 'fiber': 313, 'gap': 314, 'generalized': 315, 'infinity': 316, 'inside': 317, 'isolate': 318, 'limit': 319, 'misaligned': 320, 'multi': 321, 'numerically': 322, 'parallel': 323, 'separate': 324, 'soliton': 325, 'structurally': 326, 'thirring': 327, 'unstable': 328, 'velocity': 329}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# print key-value pairs of the corpus dictionary that has gone through bi-gramming\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f30b2-849e-4c3f-92ab-959c9048d8b3",
   "metadata": {},
   "source": [
    "After we are done creating our bi-grams, we can create tri-grams, and other n-grams by simply running the phrases model multiple times on our corpus. Bi-grams still remains the most used n-gram model, though it is worth one's time to glance over the other uses and kinds of n-gram implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3c80adf-ac0e-40a7-985d-168183113ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Removing both high frequency and low-frequency words.\n",
    "# Example: get rid of words that occur in less than 20 documents, or in more than 50% of the documents, \n",
    "dictionary.filter_extremes(no_below=len(documents), no_above=0.5)\n",
    "\n",
    "\n",
    "print(dictionary.token2id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
